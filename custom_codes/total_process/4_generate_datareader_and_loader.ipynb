{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate datareader and loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[overwrite: False] ==> Loading H36M source_list...\n",
      "[overwrite: False] ==> Loading H36M cam_param...\n",
      "[overwrite: False] ==> Loading H36M cam_3d...\n",
      "[overwrite: False] ==> Loading H36M img_3d...\n"
     ]
    }
   ],
   "source": [
    "subset = 'H36M-GT'\n",
    "datareader = DataReaderTotal(subset=subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configs/pose3d/MB_train_h36m_gt.yaml\n",
      "True\n",
      "Loading dataset...\n",
      "H36M-GT\n",
      "==> Loading H36M source_list... overwrite: False\n",
      "==> Loading H36M cam_param... overwrite: False\n",
      "==> Loading H36M cam_3d... overwrite: False\n",
      "==> Loading H36M img_3d... overwrite: False\n",
      "==> Loading H36M scale_factor... overwrite: False\n",
      "==> Loading H36M img_25d... overwrite: False\n",
      "==> Loading H36M img_2d... overwrite: False\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'MB_train_h36m_gt'\n",
    "args, opts = get_opt_args_from_model_name(checkpoint)\n",
    "train_loader, test_loader, _, _, datareader = load_dataset(args, use_new_datareader=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification with original dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "H36M-GT\n"
     ]
    }
   ],
   "source": [
    "train_loader_origin, test_loader_origin, _, _, datareader_origin = load_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = datareader.get_sliced_data()\n",
    "train_data_origin, test_data_origin, train_labels_origin, test_labels_origin = datareader_origin.get_sliced_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data shape\n",
    "assert train_data.shape == train_data_origin.shape, f'{train_data.shape} {train_data_origin.shape}'\n",
    "assert test_data.shape == test_data_origin.shape, f'{test_data.shape} {test_data_origin.shape}'\n",
    "assert train_labels.shape == train_labels_origin.shape, f'{train_labels.shape} {train_labels_origin.shape}'\n",
    "assert test_labels.shape == test_labels_origin.shape, f'{test_labels.shape} {test_labels_origin.shape}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cam_3d', '2.5d_factor', 'joint_2d', 'joint3d_image', 'joints_2.5d_image']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(datareader.dt_dataset['train'].keys() - datareader.default_data_type_lsit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:11<00:00, 50.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# check data values for each source\n",
    "for source in tqdm(list(set(datareader_origin.dt_dataset['train']['source']))):\n",
    "    loc1 = np.where(datareader_origin.dt_dataset['train']['source'] == source)[0]\n",
    "    loc2 = np.where(datareader.dt_dataset['train']['source'] == source)[0]\n",
    "    assert len(loc1) == len(loc2), f'{len(loc1)} {len(loc2)}'\n",
    "    for key in list(datareader.dt_dataset['train'].keys() - datareader.default_data_type_lsit):\n",
    "        data1 = datareader_origin.dt_dataset['train'][key][loc1].copy()\n",
    "        data2 = datareader.dt_dataset['train'][key][loc2].copy()\n",
    "        assert data1.shape == data2.shape, f'{source} {key} {data1.shape} {data2.shape}'\n",
    "        if key == '2.5d_factor': atol = 3e-02\n",
    "        elif key == 'joints_2.5d_image': atol = 20\n",
    "        else: atol = 1e-07\n",
    "        max_value = abs(data1 - data2).max()\n",
    "        max_idx = abs(data1 - data2).argmax()\n",
    "        if not np.allclose(data1, data2, atol=atol): print(f'{source} {key} {max_value}, {max_idx} {data1.flatten()[max_idx]} {data2.flatten()[max_idx]}') \n",
    "        if 'joint_2d' in key:\n",
    "            cam_params1 = datareader_origin.dt_dataset['train']['cam_param'][loc1]\n",
    "            cam_params2 = datareader.dt_dataset['train']['cam_param'][loc2]\n",
    "            #W1, H1 = np.array([cam_param['W'] for cam_param in cam_params1]), np.array([cam_param['H'] for cam_param in cam_params1])\n",
    "            W, H = np.array([cam_param['W'] for cam_param in cam_params2]), np.array([cam_param['H'] for cam_param in cam_params2])\n",
    "            normalized_data1 = datareader.normalize(data1, W, H, '2d')\n",
    "            normalized_data2 = datareader.normalize(data2, W, H, '2d')\n",
    "            assert np.allclose(normalized_data1, normalized_data2, atol=1e-07), f'{source} {key} {abs(normalized_data1 - normalized_data2).max()}, {normalized_data1[abs(normalized_data1 - normalized_data2).argmax()]}, {noramlized_data2[abs(normalized_data1 - normalized_data2).argmax()]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in glob('data/motion3d/MB3D_f243s81/*.yaml'):\n",
    "    subset = os.path.basename(item).split('.')[0]\n",
    "    if subset in blacklist: continue\n",
    "    if subset not in dt_file_mapping.keys():\n",
    "        print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TR_S1_TS_S5678\n",
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_fixed_dist_5_tr_s1_ts_s5678\n",
      "check data shape\n",
      "check data values for each source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 255.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z\n",
      "check data shape\n",
      "check data values for each source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:09<00:00, 62.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_DIST-S15678_TR_54138969_TS_OTHERS\n",
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_dist_s15678_tr_54138969_ts_others\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cam_3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 40\u001b[0m\n\u001b[1;32m     29\u001b[0m datareader_origin \u001b[38;5;241m=\u001b[39m DataReaderH36M(n_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m243\u001b[39m, \n\u001b[1;32m     30\u001b[0m                                    sample_stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     31\u001b[0m                                    data_stride_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m81\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m                                    input_mode\u001b[38;5;241m=\u001b[39mdatareader\u001b[38;5;241m.\u001b[39minput_mode, \n\u001b[1;32m     36\u001b[0m                                    gt_mode\u001b[38;5;241m=\u001b[39mdatareader\u001b[38;5;241m.\u001b[39mgt_mode)\n\u001b[1;32m     39\u001b[0m train_data, test_data, train_labels, test_labels \u001b[38;5;241m=\u001b[39m datareader\u001b[38;5;241m.\u001b[39mget_sliced_data()\n\u001b[0;32m---> 40\u001b[0m train_data_origin, test_data_origin, train_labels_origin, test_labels_origin \u001b[38;5;241m=\u001b[39m \u001b[43mdatareader_origin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sliced_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck data shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_data\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m train_data_origin\u001b[38;5;241m.\u001b[39mshape: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_data_origin\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/codes/MotionBERT/lib/data/datareader_h36m.py:133\u001b[0m, in \u001b[0;36mDataReaderH36M.get_sliced_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sliced_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    132\u001b[0m     train_data, test_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_2d()     \u001b[38;5;66;03m# train_data (1559752, 17, 3) test_data (566920, 17, 3)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     train_labels, test_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# train_labels (1559752, 17, 3) test_labels (566920, 17, 3)\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     split_id_train, split_id_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_split_id()\n\u001b[1;32m    135\u001b[0m     train_data, test_data \u001b[38;5;241m=\u001b[39m train_data[split_id_train], test_data[split_id_test]                \u001b[38;5;66;03m# (N, 27, 17, 3)\u001b[39;00m\n",
      "File \u001b[0;32m~/codes/MotionBERT/lib/data/datareader_h36m.py:65\u001b[0m, in \u001b[0;36mDataReaderH36M.read_3d\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_3d\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 65\u001b[0m     train_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt_mode\u001b[49m\u001b[43m]\u001b[49m[::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_stride, :, :\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# [N, 17, 3]\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     test_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgt_mode][::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_stride, :, :\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)    \u001b[38;5;66;03m# [N, 17, 3]\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgt_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoint3d_image\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;66;03m# normalize to [-1, 1]\u001b[39;00m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;66;03m# map to [-1, 1]\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cam_3d'"
     ]
    }
   ],
   "source": [
    "config_root = 'configs/pose3d/'\n",
    "checkpoint_root = 'checkpoint/pose3d/'\n",
    "blacklist = ['3DHP-GT-CAM_NO_FACTOR-POSEAUG_TEST_2929', \n",
    "             '3DHP-GT-CAM_NO_FACTOR-POSYNDA_TESTSET', \n",
    "             'H36M-CANONICALIZATION-GT-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678']\n",
    "\n",
    "for item in glob('data/motion3d/MB3D_f243s81/*.yaml'):\n",
    "    subset = os.path.basename(item).split('.')[0]\n",
    "    dataset_name = subset.split('-')[0]\n",
    "    if dataset_name != 'H36M': continue\n",
    "    if 'NO_FACTOR' not in subset: continue\n",
    "    if subset in blacklist: continue\n",
    "    print(subset)\n",
    "    datareader = DataReaderTotal(subset=subset, verbose=False)\n",
    "    checkpoint = f'MB_train_{datareader.dataset_name}_{datareader.input_source.lower()}'\n",
    "    if datareader.gt_mode == 'cam_3d': checkpoint += '_cam_no_factor'\n",
    "    if datareader.canonical_type is not None: checkpoint += f'_input_from_canonical_3d_{datareader.canonical_type.lower()}'\n",
    "    if 'S15678_TR_54138969_TS_OTHERS' in item: checkpoint += '_S15678_TR_54138969_TS_OTHERS'.lower()\n",
    "    elif 'TR_S1_TS_S5678' in item: checkpoint += '_TR_S1_TS_S5678'.lower()\n",
    "    elif 'TR_S03' in item: checkpoint += '_TR_S03'.lower()\n",
    "    elif 'TS_S4710' in item: checkpoint += '_TS_S4710'.lower()\n",
    "    print(checkpoint)\n",
    "    #args, opts = get_opt_args_from_model_name(checkpoint)\n",
    "    datareader_origin = DataReaderH36M(n_frames=243, \n",
    "                                       sample_stride=1, \n",
    "                                       data_stride_train=81, \n",
    "                                       data_stride_test=243, \n",
    "                                       dt_root = 'data/motion3d', \n",
    "                                       dt_file=dt_file_mapping[subset]+'.pkl', \n",
    "                                       input_mode=datareader.input_mode, \n",
    "                                       gt_mode=datareader.gt_mode)\n",
    "\n",
    "    \n",
    "    train_data, test_data, train_labels, test_labels = datareader.get_sliced_data()\n",
    "    train_data_origin, test_data_origin, train_labels_origin, test_labels_origin = datareader_origin.get_sliced_data()\n",
    "    \n",
    "    print('check data shape')\n",
    "    if train_data.shape != train_data_origin.shape: print(f'{train_data.shape} {train_data_origin.shape}')\n",
    "    if test_data.shape != test_data_origin.shape: print(f'{test_data.shape} {test_data_origin.shape}')\n",
    "    if train_labels.shape != train_labels_origin.shape: print(f'{train_labels.shape} {train_labels_origin.shape}')\n",
    "    if test_labels.shape != test_labels_origin.shape: print(f'{test_labels.shape} {test_labels_origin.shape}')\n",
    "    \n",
    "    print('check data values for each source')\n",
    "    for source in tqdm(list(set(datareader_origin.dt_dataset['train']['source']))):\n",
    "        loc1 = np.where(datareader_origin.dt_dataset['train']['source'] == source)[0]\n",
    "        loc2 = np.where(datareader.dt_dataset['train']['source'] == source)[0]\n",
    "        for key in list(datareader.dt_dataset['train'].keys() - datareader.default_data_type_lsit):\n",
    "            data1 = datareader_origin.dt_dataset['train'][key][loc1]\n",
    "            data2 = datareader.dt_dataset['train'][key][loc2]\n",
    "            #print(key, data1.shape, data2.shape)\n",
    "            assert np.allclose(data1, data2, atol=1e-07), f'{source} {key} {abs(data1 - data2).max()}'\n",
    "            if 'joint_2d' in key:\n",
    "                cam_params1 = datareader_origin.dt_dataset['train']['cam_param'][loc1]\n",
    "                cam_params2 = datareader.dt_dataset['train']['cam_param'][loc2]\n",
    "                #W1, H1 = np.array([cam_param['W'] for cam_param in cam_params1]), np.array([cam_param['H'] for cam_param in cam_params1])\n",
    "                W, H = np.array([cam_param['W'] for cam_param in cam_params2]), np.array([cam_param['H'] for cam_param in cam_params2])\n",
    "                normalized_data1 = datareader.normalize(data1, W, H, '2d')\n",
    "                normalized_data2 = datareader.normalize(data2, W, H, '2d')\n",
    "                assert np.allclose(normalized_data1, normalized_data2, atol=1e-07), f'{source} {key} {abs(normalized_data1 - normalized_data2).max()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['S1', 'S5', 'S6', 'S7', 'S8'],\n",
       " ['S1', 'S5', 'S6', 'S7', 'S8'],\n",
       " ['cam_3d',\n",
       "  'joint_2d_from_canonical_3d',\n",
       "  'cam_3d_from_canonical_3d',\n",
       "  'source',\n",
       "  'cam_param',\n",
       "  'camera_name',\n",
       "  'action',\n",
       "  'confidence'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datareader.train_subject, datareader.test_subject, datareader.data_type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datareader.dt_dataset['train']['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_DIST-S15678_TR_54138969_TS_OTHERS'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cam_list': [], 'canonical_type': 'same_dist', 'data_type_list': ['cam_3d', 'joint_2d_from_canonical_3d', 'cam_3d_from_canonical_3d'], 'dataset_name': 'h36m', 'gt_mode': 'cam_3d', 'input_mode': 'joint_2d_from_canonical_3d', 'input_source': 'GT', 'test_cam': ['60457274', '55011271', '58860488'], 'test_subject': ['S1', 'S5', 'S6', 'S7', 'S8'], 'train_cam': ['54138969'], 'train_subject': ['S1', 'S5', 'S6', 'S7', 'S8']}\n"
     ]
    }
   ],
   "source": [
    "datareader = DataReaderTotal(subset='H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_DIST-S15678_TR_54138969_TS_OTHERS',\n",
    "                             verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cam_list': [],\n",
       " 'canonical_type': 'same_dist',\n",
       " 'data_type_list': ['cam_3d',\n",
       "  'joint_2d_from_canonical_3d',\n",
       "  'cam_3d_from_canonical_3d'],\n",
       " 'dataset_name': 'h36m',\n",
       " 'gt_mode': 'cam_3d',\n",
       " 'input_mode': 'joint_2d_from_canonical_3d',\n",
       " 'input_source': 'GT',\n",
       " 'test_cam': ['60457274', '55011271', '58860488'],\n",
       " 'test_subject': ['S1', 'S5', 'S6', 'S7', 'S8'],\n",
       " 'train_cam': ['54138969'],\n",
       " 'train_subject': ['S1', 'S5', 'S6', 'S7', 'S8']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datareader.yaml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['joint_2d_from_canonical_3d', 'confidence', 'joint3d_image_from_canonical_3d', 'joints_2.5d_image_from_canonical_3d', '2.5d_factor_from_canonical_3d', 'camera_name', 'action', 'source', 'frame', 'world_3d', 'cam_3d_from_canonical_3d', 'cam_param', 'world_3from_canonical_3d'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datareader_origin.dt_dataset['train'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple subset - DataReaderTotalGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data.datareader_total import DataReaderTotalGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[overwrite: False] ==> Loading H36M source_list...\n",
      "[overwrite: False] ==> Loading H36M cam_param...\n",
      "[overwrite: False] ==> Loading H36M cam_3d_steprot_1.0...\n",
      "[overwrite: False] ==> Loading H36M img_2d_canonical_same_z_steprot_1.0...\n",
      "[overwrite: False] ==> Loading H36M cam_3d_canonical_same_z_steprot_1.0...\n",
      "[overwrite: False] ==> Loading H36M source_list...\n",
      "[overwrite: False] ==> Loading H36M cam_param...\n",
      "[overwrite: False] ==> Loading H36M cam_3d...\n",
      "[overwrite: False] ==> Loading H36M img_2d_canonical_same_z...\n",
      "[overwrite: False] ==> Loading H36M cam_3d_canonical_same_z...\n"
     ]
    }
   ],
   "source": [
    "subset_list = ['H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-STEP_ROT_1-TR_S1_TS_S5678', 'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678']\n",
    "datareader = DataReaderTotalGroup(subset_list=subset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configs/pose3d/MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z_input_centering_steprot_1+original_tr_s1_ts_s5678.yaml\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z_input_centering_steprot_1+original_tr_s1_ts_s5678'\n",
    "args, opts = get_opt_args_from_model_name(checkpoint, mode='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = datareader.get_sliced_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10312, 243, 17, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2622752"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datareader.read_hw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_frames, action_clips, factor_clips, source_clips, frame_clips, gt_clips, actions = datareader.datareader['H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-STEP_ROT_1-TR_S1_TS_S5678'].get_clip_info(args, int(len(test_labels)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5156, 243),\n",
       " (5156, 243),\n",
       " (5156, 243),\n",
       " (5156, 243),\n",
       " (5156, 243, 17, 3),\n",
       " (1311376,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_clips.shape, factor_clips.shape, source_clips.shape, frame_clips.shape, gt_clips.shape, actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_frames, action_clips, factor_clips, source_clips, frame_clips, gt_clips, actions = datareader.get_clip_info(args, len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10312, 243),\n",
       " (10312, 243),\n",
       " (10312, 243),\n",
       " (10312, 243),\n",
       " (10312, 243, 17, 3),\n",
       " (2622752,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_clips.shape, factor_clips.shape, source_clips.shape, frame_clips.shape, gt_clips.shape, actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
       "       256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268,\n",
       "       269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
       "       282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
       "       295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
       "       308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
       "       321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
       "       334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
       "       347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359,\n",
       "       360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n",
       "       373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n",
       "       386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n",
       "       399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
       "       412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424,\n",
       "       425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
       "       438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
       "       451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
       "       464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
       "       477, 478, 479, 480, 481, 482, 483, 484, 485])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_clips[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motionbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
