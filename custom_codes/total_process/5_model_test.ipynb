{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "from common_import import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate single experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original\n",
      "Loading checkpoint checkpoint/pose3d/MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original/best_epoch.bin\n",
      "Loading dataset...\n",
      "FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_CANONICAL_PCL_ORIGINAL-ALL_TEST\n",
      "[overwrite: False] ==> Loading FIT3D source_list...\n",
      "[overwrite: False] ==> Loading FIT3D cam_param...\n",
      "[overwrite: False] ==> Loading FIT3D cam_3d...\n",
      "[overwrite: False] ==> Loading FIT3D cam_3d_canonical_pcl_original...\n",
      "[overwrite: False] ==> Loading FIT3D img_2d_canonical_pcl_original...\n",
      "INFO: Testing\n",
      "No epoch information in the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [02:28<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No eval_keypoint. Use part list\n",
      "Part: whole\n",
      "Protocol #1 Error (MPJPE): 153.84440685517265 mm\n",
      "Protocol #2 Error (P-MPJPE): 105.37305581226684 mm\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "checkpoint_name = 'MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original'\n",
    "args, opts = get_opt_args_from_model_name(checkpoint_name, verbose=False)\n",
    "model_pos, chk_filename, checkpoint = load_model(opts, args)\n",
    "# load dataset\n",
    "subset = 'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_CANONICAL_PCL_ORIGINAL'\n",
    "if 'PCL' in subset: args.fix_orientation_pred = True # load dataset\n",
    "args.subset_list = [subset]\n",
    "train_loader, test_loader, _, _, datareader = load_dataset(args, use_new_datareader=True)\n",
    "e1, e2, results_all, inputs_all, gts_all, total_result_dict = evaluate(args, model_pos, test_loader, datareader, checkpoint, only_one_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "save = True\n",
    "if save:\n",
    "    save_folder = f'/home/hrai/codes/MotionBERT/saved_results/{checkpoint_name}'\n",
    "    if not os.path.exists(save_folder): os.makedirs(save_folder)\n",
    "    save_path = os.path.join(save_folder, f'{subset}.pkl')\n",
    "    results_dict = {'results_all': results_all, 'total_result_dict': total_result_dict, 'e1': e1, 'e2': e2} # 'gts_all': gts_all, 'inputs_all': inputs_all, \n",
    "    savepkl(results_dict, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update result_dict\n",
    "update_result_dict = True\n",
    "if update_result_dict:\n",
    "    result_dict = readpkl('result_dict.pkl')\n",
    "    try: del result_dict[checkpoint_name][subset]\n",
    "    except: print('subset not found')\n",
    "    savepkl(result_dict, 'result_dict.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and save all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = os.listdir('saved_results')\n",
    "checkpoint_list = os.listdir('checkpoint/pose3d')\n",
    "whitelist_checkpoint = []\n",
    "for item in os.listdir('configs/pose3d'):\n",
    "    checkpoint = item.split('.yaml')[0]\n",
    "    if 'cam_no_factor' not in checkpoint: continue\n",
    "    if checkpoint in blacklist_checkpoint: continue\n",
    "    if checkpoint not in checkpoint_list:\n",
    "        print(f'[Need to be trained] {checkpoint}')\n",
    "        continue\n",
    "    if checkpoint not in experiment_list:\n",
    "        whitelist_checkpoint.append(checkpoint)\n",
    "        # create empty file\n",
    "        with open(f'experiments/{checkpoint}.txt', 'w') as f:\n",
    "            pass\n",
    "    else:\n",
    "        subset_list = []\n",
    "        with open(f'experiments/{checkpoint}.txt', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                subset = line.split('\\n')[0]\n",
    "                subset_list.append(subset)\n",
    "        if len(subset_list) == 0:\n",
    "            print(f'[No subset fou  d] {checkpoint}')\n",
    "            whitelist_checkpoint.append(checkpoint)\n",
    "        for subset in subset_list:\n",
    "            if not os.path.exists(f'saved_results/{checkpoint}/{subset}.pkl'):\n",
    "                print(f'[Result not found] {checkpoint} - {subset}')\n",
    "                if checkpoint not in whitelist_checkpoint:\n",
    "                    whitelist_checkpoint.append(checkpoint)\n",
    "\n",
    "print('\\nCheckpoints to evaluate:')\n",
    "whitelist_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original\n",
      "Experiment path: /home/hrai/codes/MotionBERT/experiments/MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original.txt\n",
      "Config# path: /home/hrai/codes/MotionBERT/configs/pose3d/MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original.yaml\n"
     ]
    }
   ],
   "source": [
    "whitelist_checkpoint = [\n",
    "    #'MB_train_h36m_gt_cam_no_factor',\n",
    "    #'MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z_input_centering',\n",
    "    #'MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_revolute_input_centering',\n",
    "    #'MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_revolute_no_Rz_input_centering',\n",
    "    #'MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_revolute_input_centering_tr_s1_ts_s5678',\n",
    "    #'MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_input_centering_fix_orientation_pred_tr_s1_ts_s5678',\n",
    "    #'MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_input_centering_fix_orientation_pred',\n",
    "    'MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original',\n",
    "]\n",
    "\n",
    "# check experiment file\n",
    "motionbert_root = f'/home/{user}/codes/MotionBERT'\n",
    "for checkpoint in whitelist_checkpoint:\n",
    "    experiment_path = f'{motionbert_root}/experiments/{checkpoint}.txt'\n",
    "    config_path = f'{motionbert_root}/configs/pose3d/{checkpoint}.yaml'\n",
    "    print(f'{checkpoint}')\n",
    "    if os.path.exists(experiment_path): print(f'Experiment path: {experiment_path}')\n",
    "    else:\n",
    "        print(f'[No experiment path] {experiment_path}')\n",
    "        with open(experiment_path, 'w') as f: pass\n",
    "    if os.path.exists(config_path): print(f'Config# path: {config_path}')\n",
    "    else: print(f'[No config path] {config_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 30/97 [10:41<22:45, 20.39s/it]"
     ]
    }
   ],
   "source": [
    "experiment_root = f'/home/{user}/codes/MotionBERT/experiments'\n",
    "for item in tqdm(glob(experiment_root+'/*.txt')):\n",
    "    checkpoint_name = os.path.basename(item).split('.txt')[0]\n",
    "    save_folder = f'/home/hrai/codes/MotionBERT/saved_results/{checkpoint_name}'\n",
    "    subset_list = []\n",
    "    with open(item, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            subset = line.strip()\n",
    "            subset_list.append(subset)\n",
    "\n",
    "    for subset in subset_list:\n",
    "        save_path = os.path.join(save_folder, f'{subset}.pkl')\n",
    "        if not os.path.exists(save_path): continue\n",
    "        results_dict = readpkl(save_path)\n",
    "        #print(checkpoint_name, subset, results_dict.keys())\n",
    "        if 'gts_all' in results_dict.keys(): del results_dict['gts_all']\n",
    "        if 'inputs_all' in results_dict.keys(): del results_dict['inputs_all']\n",
    "        savepkl(results_dict, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hrai/codes/PerspectiveCropLayers/src'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original\n",
      "Loading checkpoint checkpoint/pose3d/MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original/best_epoch.bin\n",
      "/home/hrai/codes/MotionBERT/saved_results/MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original/3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_CANONICAL_PCL_ORIGINAL-TEST_TS1_6.pkl exists\n",
      "/home/hrai/codes/MotionBERT/saved_results/MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original/3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_CANONICAL_PCL_ORIGINAL-TEST_TS1_6_UNIV.pkl exists\n",
      "Loading dataset...\n",
      "3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_CANONICAL_PCL_ORIGINAL-TEST_ALL_TRAIN\n",
      "[overwrite: False] ==> Loading 3DHP source_list...\n",
      "[overwrite: False] ==> Loading 3DHP cam_param...\n",
      "[overwrite: False] ==> Loading 3DHP cam_3d...\n",
      "[overwrite: False] ==> Loading 3DHP cam_3d_canonical_pcl_original...\n",
      "[overwrite: False] ==> Loading 3DHP img_2d_canonical_pcl_original...\n",
      "INFO: Testing\n",
      "No epoch information in the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [01:30<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No eval_keypoint. Use part list\n",
      "Part: whole\n",
      "Protocol #1 Error (MPJPE): 72.48222253274153 mm\n",
      "Protocol #2 Error (P-MPJPE): 56.477456784743836 mm\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "experiment_root = f'/home/{user}/codes/MotionBERT/experiments'\n",
    "for item in glob(experiment_root+'/*.txt'):\n",
    "    checkpoint_name = os.path.basename(item).split('.txt')[0]\n",
    "    if checkpoint_name in blacklist_checkpoint: continue\n",
    "    if len(whitelist_checkpoint) > 0 and checkpoint_name not in whitelist_checkpoint: continue\n",
    "    if 'cam_no_factor' not in checkpoint_name: continue\n",
    "    save_folder = f'/home/hrai/codes/MotionBERT/saved_results/{checkpoint_name}'\n",
    "    if not os.path.exists(save_folder): os.makedirs(save_folder)\n",
    "\n",
    "    # load model\n",
    "    args, opts = get_opt_args_from_model_name(checkpoint_name, verbose=False)\n",
    "    model_pos, chk_filename, checkpoint = load_model(opts, args)\n",
    "\n",
    "    subset_list = []\n",
    "    with open(item, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            subset = line.strip()\n",
    "            subset_list.append(subset)\n",
    "\n",
    "    for subset in subset_list:\n",
    "        if '3DHP' not in subset: continue\n",
    "        if 'PCL' in subset: args.fix_orientation_pred = True\n",
    "        save_path = os.path.join(save_folder, f'{subset}.pkl')\n",
    "        if os.path.exists(save_path):\n",
    "            print(f'{save_path} exists')\n",
    "            continue\n",
    "        try:\n",
    "            # load dataset\n",
    "            args.subset_list = [subset]\n",
    "            train_loader, test_loader, _, _, datareader = load_dataset(args, use_new_datareader=True)\n",
    "            # evaluation\n",
    "            e1, e2, results_all, inputs_all, gts_all, total_result_dict = evaluate(args, model_pos, test_loader, datareader, checkpoint, only_one_batch=False)\n",
    "            # save results\n",
    "            results_dict = {'results_all': results_all, 'total_result_dict': total_result_dict, 'e1': e1, 'e2': e2} # 'gts_all': gts_all, 'inputs_all': inputs_all, \n",
    "            savepkl(results_dict, save_path)\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cherrypick e1, e1 -> result_dict.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/hrai/codes/MotionBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m readpkl(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_dict.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m whitelist_checkpoint:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m result_dict[item]\n\u001b[1;32m      4\u001b[0m savepkl(result_dict, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_dict.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MB_train_h36m_gt_cam_no_factor_input_from_canonical_pcl_original'"
     ]
    }
   ],
   "source": [
    "result_dict = readpkl('result_dict.pkl')\n",
    "for item in whitelist_checkpoint:\n",
    "    del result_dict[item]\n",
    "savepkl(result_dict, 'result_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading result_dict.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 169.55it/s]\n"
     ]
    }
   ],
   "source": [
    "blacklist_checkpoint = ['MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z_s15678_tr_54138969_ts_others']\n",
    "\n",
    "def update_result_dict(blacklist_checkpoint):\n",
    "    if os.path.exists('result_dict.pkl'):\n",
    "        print('Loading result_dict.pkl')\n",
    "        result_dict = readpkl('result_dict.pkl')\n",
    "    else:\n",
    "        result_dict = {}\n",
    "    result_root = '/home/hrai/codes/MotionBERT/saved_results'\n",
    "    checkpoint_list = os.listdir(result_root)\n",
    "    for checkpoint in tqdm(checkpoint_list):\n",
    "        if checkpoint in blacklist_checkpoint: continue # skip\n",
    "        if checkpoint not in result_dict.keys(): result_dict[checkpoint] = {} # create new key if not exists\n",
    "        checkpoint_root = os.path.join(result_root, checkpoint)\n",
    "        subset_list = glob(checkpoint_root+'/*.pkl')\n",
    "        for item in subset_list:\n",
    "            subset = os.path.basename(item).split('.pkl')[0]\n",
    "            if subset in result_dict[checkpoint].keys():\n",
    "                #print(f'{subset} exists')\n",
    "                continue\n",
    "            result = readpkl(item)\n",
    "            result_dict[checkpoint][subset] = {'e1': result['e1'], 'e2': result['e2']}\n",
    "        # remove key if not in subset_list\n",
    "        for key in list(result_dict[checkpoint].keys()):\n",
    "            if key not in [os.path.basename(item).split('.pkl')[0] for item in subset_list]:\n",
    "                del result_dict[checkpoint][key]\n",
    "\n",
    "    savepkl(result_dict, 'result_dict.pkl')\n",
    "\n",
    "update_result_dict(blacklist_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prettytable\n",
    "\n",
    "# PrettyTable 객체 생성 및 필드 설정\n",
    "pt = prettytable.PrettyTable()\n",
    "pt.field_names = ['Checkpoint', 'Subset', 'E1', 'E2']\n",
    "\n",
    "# 데이터를 리스트에 수집\n",
    "data = []\n",
    "for key in result_dict.keys():\n",
    "    for subset in result_dict[key].keys():\n",
    "        if 'UNIV' not in subset: \n",
    "            continue\n",
    "        e1 = float(result_dict[key][subset]['e1'])\n",
    "        e2 = float(result_dict[key][subset]['e2'])\n",
    "        data.append([key, subset, e1, e2])\n",
    "\n",
    "# 데이터를 Subset 1순위, E1 2순위로 정렬\n",
    "data_sorted = sorted(data, key=lambda x: (x[1], x[2]))\n",
    "\n",
    "# 정렬된 데이터를 테이블에 추가\n",
    "for row in data_sorted:\n",
    "    pt.add_row([row[0], row[1], f'{row[2]:.2f}', f'{row[3]:.2f}'])\n",
    "\n",
    "# 테이블 출력\n",
    "print(pt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motionbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
