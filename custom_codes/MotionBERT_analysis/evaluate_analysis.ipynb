{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python train.py \\\n",
    "# --config configs/pose3d/MB_train_h36m.yaml \\\n",
    "# --evaluate checkpoint/pose3d/MB_train_h36m/best_epoch.bin         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "user = getpass.getuser()\n",
    "motionbert_root = '/home/{}/codes/MotionBERT'.format(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import errno\n",
    "import math\n",
    "import pickle\n",
    "import tensorboardX\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import copy\n",
    "import random\n",
    "import prettytable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.chdir(motionbert_root)\n",
    "\n",
    "from lib.utils.tools import *\n",
    "from lib.utils.learning import *\n",
    "from lib.utils.utils_data import flip_data\n",
    "from lib.data.dataset_motion_2d import PoseTrackDataset2D, InstaVDataset2D\n",
    "from lib.data.dataset_motion_3d import MotionDataset3D\n",
    "from lib.data.augmentation import Augmenter2D\n",
    "from lib.data.datareader_h36m import DataReaderH36M  \n",
    "from lib.model.loss import *\n",
    "\n",
    "from train import set_random_seed, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'MB_ft_h36m'\n",
    "#model_name = 'MB_train_h36m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "opts = easydict.EasyDict({\n",
    "    \"config\": \"configs/pose3d/{}.yaml\".format(model_name),\n",
    "    \"checkpoint\": 'checkpoint',\n",
    "    \"pretrained\": 'checkpoint',\n",
    "    \"resume\": '',\n",
    "    \"evaluate\": 'checkpoint/pose3d/{}/best_epoch.bin'.format(model_name),\n",
    "    \"selection\": 'best_epoch.bin',\n",
    "    \"seed\": 0,\n",
    "    })\n",
    "set_random_seed(opts.seed)\n",
    "args = get_config(opts.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(opts.checkpoint)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise RuntimeError('Unable to create checkpoint directory:', opts.checkpoint)\n",
    "train_writer = tensorboardX.SummaryWriter(os.path.join(opts.checkpoint, \"logs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H36M-SH']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.subset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "print('Loading dataset...')\n",
    "trainloader_params = {\n",
    "        'batch_size': args.batch_size,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 12,\n",
    "        'pin_memory': True,\n",
    "        'prefetch_factor': 4,\n",
    "        'persistent_workers': True\n",
    "}\n",
    "\n",
    "testloader_params = {\n",
    "        'batch_size': args.batch_size,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 12,\n",
    "        'pin_memory': True,\n",
    "        'prefetch_factor': 4,\n",
    "        'persistent_workers': True\n",
    "}\n",
    "\n",
    "train_dataset = MotionDataset3D(args, args.subset_list, 'train')\n",
    "test_dataset = MotionDataset3D(args, args.subset_list, 'test')\n",
    "train_loader_3d = DataLoader(train_dataset, **trainloader_params)\n",
    "test_loader = DataLoader(test_dataset, **testloader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "datareader = DataReaderH36M(n_frames=args.clip_len, sample_stride=args.sample_stride, data_stride_train=args.data_stride, data_stride_test=args.clip_len, dt_root = 'data/motion3d', dt_file=args.dt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Trainable parameter count: 42466317\n"
     ]
    }
   ],
   "source": [
    "min_loss = 100000\n",
    "model_backbone = load_backbone(args)\n",
    "model_params = 0\n",
    "for parameter in model_backbone.parameters():\n",
    "    model_params = model_params + parameter.numel()\n",
    "print('INFO: Trainable parameter count:', model_params)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model_backbone = nn.DataParallel(model_backbone)\n",
    "    model_backbone = model_backbone.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, '', 'checkpoint/pose3d/MB_ft_h36m/best_epoch.bin')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.finetune, opts.resume, opts.evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/pose3d/MB_ft_h36m/best_epoch.bin\n"
     ]
    }
   ],
   "source": [
    "chk_filename = opts.evaluate if opts.evaluate else opts.resume\n",
    "print('Loading checkpoint', chk_filename)\n",
    "checkpoint = torch.load(chk_filename, map_location=lambda storage, loc: storage)\n",
    "model_backbone.load_state_dict(checkpoint['model_pos'], strict=True)\n",
    "model_pos = model_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.partial_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint/pose3d/MB_ft_h36m/best_epoch.bin'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts.evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args, model_pos, test_loader, datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False, False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.no_conf, args.flip, args.rootrel, args.gt_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.flip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [01:30<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "results_all = []\n",
    "model_pos.eval()            \n",
    "with torch.no_grad():\n",
    "    for batch_input, batch_gt in tqdm(test_loader):\n",
    "        N, T = batch_gt.shape[:2] # B, N\n",
    "        if torch.cuda.is_available():\n",
    "            batch_input = batch_input.cuda()\n",
    "        if args.flip:    \n",
    "            batch_input_flip = flip_data(batch_input)\n",
    "            predicted_3d_pos_1 = model_pos(batch_input)\n",
    "            predicted_3d_pos_flip = model_pos(batch_input_flip)\n",
    "            predicted_3d_pos_2 = flip_data(predicted_3d_pos_flip)                   # Flip back\n",
    "            predicted_3d_pos = (predicted_3d_pos_1+predicted_3d_pos_2) / 2\n",
    "        else:\n",
    "            predicted_3d_pos = model_pos(batch_input)\n",
    "        results_all.append(predicted_3d_pos.cpu().numpy())\n",
    "results_all = np.concatenate(results_all)\n",
    "results_all = datareader.denormalize(results_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('custom_codes/{}_result_denormalized.npy'.format(model_name), results_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = np.load('custom_codes/{}_result_denormalized.npy'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, split_id_test = datareader.get_split_id()\n",
    "actions = np.array(datareader.dt_dataset['test']['action'])\n",
    "factors = np.array(datareader.dt_dataset['test']['2.5d_factor'])\n",
    "gts = np.array(datareader.dt_dataset['test']['joints_2.5d_image'])\n",
    "sources = np.array(datareader.dt_dataset['test']['source'])\n",
    "\n",
    "num_test_frames = len(actions)\n",
    "frames = np.array(range(num_test_frames))\n",
    "action_clips = actions[split_id_test]\n",
    "factor_clips = factors[split_id_test]\n",
    "source_clips = sources[split_id_test]\n",
    "frame_clips = frames[split_id_test]\n",
    "gt_clips = gts[split_id_test]\n",
    "assert len(results_all)==len(action_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_all = np.zeros(num_test_frames)\n",
    "e2_all = np.zeros(num_test_frames)\n",
    "oc = np.zeros(num_test_frames)\n",
    "action_names = sorted(set(datareader.dt_dataset['test']['action']))\n",
    "block_list = ['s_09_act_05_subact_02', \n",
    "                's_09_act_10_subact_02', \n",
    "                's_09_act_13_subact_01']\n",
    "\n",
    "for idx in range(len(action_clips)):\n",
    "    source = source_clips[idx][0][:-6]\n",
    "    if source in block_list:\n",
    "        continue\n",
    "    frame_list = frame_clips[idx] # numpy.ndarray\n",
    "    action = action_clips[idx][0]\n",
    "    factor = factor_clips[idx][:,None,None]\n",
    "    gt = gt_clips[idx]\n",
    "    pred = results_all[idx]\n",
    "    pred *= factor\n",
    "    \n",
    "    # Root-relative Errors\n",
    "    pred = pred - pred[:,0:1,:] # (243, 17, 3)\n",
    "    gt = gt - gt[:,0:1,:] # (243, 17, 3)\n",
    "    err1 = mpjpe(pred, gt) # (243,)\n",
    "    err2 = p_mpjpe(pred, gt) # (243,)\n",
    "    e1_all[frame_list] += err1 # numpy.ndarray를 인덱스로 사용 가능\n",
    "    e2_all[frame_list] += err2\n",
    "    oc[frame_list] += 1 # 프레임별 카운팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results_procrustes = {}\n",
    "\n",
    "for action in action_names:\n",
    "    results[action] = []\n",
    "    results_procrustes[action] = []\n",
    "\n",
    "for idx in range(num_test_frames):\n",
    "    if e1_all[idx] > 0:\n",
    "        err1 = e1_all[idx] / oc[idx]\n",
    "        err2 = e2_all[idx] / oc[idx]\n",
    "        action = actions[idx]\n",
    "        results[action].append(err1)\n",
    "        results_procrustes[action].append(err2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| test_name |     Direction      |      Discuss      |       Eating       |       Greet        |       Phone       |       Photo       |        Pose        |      Purchase      |      Sitting       |    SittingDown    |       Smoke       |        Wait        |        Walk        |      WalkDog       |      WalkTwo       |\n",
      "+-----------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|     P1    | 34.85464262441107  |  36.8028792188831 | 37.345128501607505 | 31.783434563172044 | 39.09325373546488 | 45.63817709807015 | 36.11799147917247  | 33.55319876951755  | 48.85987257154931  | 53.91462464656722 | 39.26587034989688 | 36.55672163613903  | 24.233381568369342 | 34.68845244337738  | 24.971664710339205 |\n",
      "|     P2    | 29.550395522833853 | 31.36181267885967 | 32.000212474476626 | 27.02191840065196  | 32.86676071618676 | 37.22919319886309 | 29.883551178354985 | 29.694735003467862 | 41.019934750841024 | 48.24180947885773 | 34.31341520631264 | 30.123841932312704 | 21.273310933829336 | 30.200217992644216 | 21.807412084689357 |\n",
      "+-----------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "Protocol #1 Error (MPJPE): 37.1786195944358 mm\n",
      "Protocol #2 Error (P-MPJPE): 31.772568103545453 mm\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "final_result = []\n",
    "final_result_procrustes = []\n",
    "summary_table = prettytable.PrettyTable()\n",
    "summary_table.field_names = ['test_name'] + action_names\n",
    "for action in action_names:\n",
    "    final_result.append(np.mean(results[action]))\n",
    "    final_result_procrustes.append(np.mean(results_procrustes[action]))\n",
    "summary_table.add_row(['P1'] + final_result)\n",
    "summary_table.add_row(['P2'] + final_result_procrustes)\n",
    "print(summary_table)\n",
    "e1 = np.mean(np.array(final_result))\n",
    "e2 = np.mean(np.array(final_result_procrustes))\n",
    "print('Protocol #1 Error (MPJPE):', e1, 'mm')\n",
    "print('Protocol #2 Error (P-MPJPE):', e2, 'mm')\n",
    "print('----------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### denormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = results_all\n",
    "n_clips = test_data.shape[0]\n",
    "test_hw = datareader.get_hw()\n",
    "data = test_data.reshape([n_clips, -1, 17, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2228)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(test_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(data):\n",
    "    res_w, res_h = test_hw[idx]\n",
    "    data[idx, :, :, :2] = (data[idx, :, :, :2] + np.array([1, res_h / res_w])) * res_w / 2\n",
    "    data[idx, :, :, 2:] = data[idx, :, :, 2:] * res_w / 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, split_id_test = datareader.get_split_id()\n",
    "split_id_test = split_id_test[:len(results_all)]\n",
    "actions = np.array(datareader.dt_dataset['test']['action'])\n",
    "factors = np.array(datareader.dt_dataset['test']['2.5d_factor'])\n",
    "gts = np.array(datareader.dt_dataset['test']['joints_2.5d_image'])\n",
    "sources = np.array(datareader.dt_dataset['test']['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7776"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_all)*243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7776 is out of bounds for axis 0 with size 7776",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m factor_clips \u001b[39m=\u001b[39m factors[split_id_test]\n\u001b[1;32m      5\u001b[0m source_clips \u001b[39m=\u001b[39m sources[split_id_test]\n\u001b[0;32m----> 6\u001b[0m frame_clips \u001b[39m=\u001b[39m frames[split_id_test]\n\u001b[1;32m      7\u001b[0m gt_clips \u001b[39m=\u001b[39m gts[split_id_test]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7776 is out of bounds for axis 0 with size 7776"
     ]
    }
   ],
   "source": [
    "num_test_frames = len(results_all)*243 # 566920\n",
    "frames = np.array(range(num_test_frames))\n",
    "action_clips = actions[split_id_test]\n",
    "factor_clips = factors[split_id_test]\n",
    "source_clips = sources[split_id_test]\n",
    "frame_clips = frames[split_id_test]\n",
    "gt_clips = gts[split_id_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m e1_all \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros(results_all)\n\u001b[1;32m      2\u001b[0m e2_all \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(results_all)\n\u001b[1;32m      3\u001b[0m oc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(results_all)\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "e1_all = np.zeros(results_all)\n",
    "e2_all = np.zeros(results_all)\n",
    "oc = np.zeros(results_all)\n",
    "results = {}\n",
    "results_procrustes = {}\n",
    "action_names = sorted(set(datareader.dt_dataset['test']['action']))\n",
    "for action in action_names:\n",
    "    results[action] = []\n",
    "    results_procrustes[action] = []\n",
    "block_list = ['s_09_act_05_subact_02', \n",
    "                's_09_act_10_subact_02', \n",
    "                's_09_act_13_subact_01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(results_all)):\n",
    "    source = source_clips[idx][0][:-6]\n",
    "    if source in block_list:\n",
    "        continue\n",
    "    frame_list = frame_clips[idx]\n",
    "    action = action_clips[idx][0]\n",
    "    factor = factor_clips[idx][:,None,None]\n",
    "    gt = gt_clips[idx]\n",
    "    pred = results_all[idx]\n",
    "    pred *= factor\n",
    "    \n",
    "    # Root-relative Errors\n",
    "    pred = pred - pred[:,0:1,:]\n",
    "    gt = gt - gt[:,0:1,:]\n",
    "    err1 = mpjpe(pred, gt)\n",
    "    err2 = p_mpjpe(pred, gt)\n",
    "    e1_all[frame_list] += err1\n",
    "    e2_all[frame_list] += err2\n",
    "    oc[frame_list] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566920"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(num_test_frames):\n",
    "    if e1_all[idx] > 0:\n",
    "        err1 = e1_all[idx] / oc[idx]\n",
    "        err2 = e2_all[idx] / oc[idx]\n",
    "        action = actions[idx]\n",
    "        results[action].append(err1)\n",
    "        results_procrustes[action].append(err2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motionbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "996031ba2a0f3c1298a339c0299835a7fe1ef636d9e79358bc474ca43ed2ac18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
