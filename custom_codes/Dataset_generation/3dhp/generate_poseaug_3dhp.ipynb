{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import os, sys, getpass\n",
    "user = getpass.getuser()\n",
    "sys.path.append(f'/home/{user}/codes/hpe_library/')\n",
    "from lib_import import *\n",
    "from my_utils import *\n",
    "os.chdir('/home/hrai/codes/MotionBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('/home/hrai/Datasets/HAAI/3DHP/poseaug/test_3dhp.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nose_keypoint(pose2d, pose3d):\n",
    "    assert pose2d.shape[1] == 16, \"pose2d shape should be (N, 16, 2)\"\n",
    "    assert pose3d.shape[1] == 16, \"pose3d shape should be (N, 16, 3)\"\n",
    "    new_pose2d = np.zeros((pose2d.shape[0], 17, 2))\n",
    "    new_pose3d = np.zeros((pose3d.shape[0], 17, 3))\n",
    "    \n",
    "    new_pose2d[:, 9, :]   = (pose2d[:, 8, :] + pose2d[:, 9, :])/2\n",
    "    new_pose2d[:, 0:9, :] =  pose2d[:, 0:9, :] # 0-8\n",
    "    new_pose2d[:, 10:, :] =  pose2d[:, 9:, :]\n",
    "    new_pose3d[:, 9, :]   = (pose3d[:, 8, :] + pose3d[:, 9, :])/2\n",
    "    new_pose3d[:, 0:9, :] =  pose3d[:, 0:9, :] # 0-8\n",
    "    new_pose3d[:, 10:, :] =  pose3d[:, 9:, :]\n",
    "    \n",
    "    return new_pose2d, new_pose3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2929, 16, 2) (2929, 16, 3)\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.18546074e-01  3.13477341e-04 -2.11239503e-02]\n",
      " [-1.32954629e-01  4.72305861e-01  9.51011342e-02]\n",
      " [-1.53749059e-01  7.97275637e-01  2.73700839e-01]\n",
      " [ 1.18546074e-01 -3.13477341e-04  2.11239503e-02]\n",
      " [ 9.63895564e-02  4.76514175e-01  1.18332277e-01]\n",
      " [ 8.19574585e-02  8.15433042e-01  2.69529812e-01]\n",
      " [ 3.51583778e-03 -2.25936963e-01 -2.37523839e-02]\n",
      " [ 1.09323380e-02 -4.77327568e-01 -6.82279314e-02]\n",
      " [ 1.94244175e-02 -5.97434048e-01 -1.15704790e-01]\n",
      " [ 2.79164970e-02 -7.17540529e-01 -1.63181649e-01]\n",
      " [ 1.48406677e-01 -4.23220425e-01 -4.78323932e-02]\n",
      " [ 4.45392422e-01 -4.23356569e-01 -4.76242754e-02]\n",
      " [ 6.67393346e-01 -4.49128482e-01 -7.26417617e-02]\n",
      " [-1.21724075e-01 -4.25580827e-01 -6.81152010e-02]\n",
      " [-4.17845264e-01 -4.46781087e-01 -6.01286828e-02]\n",
      " [-6.39455101e-01 -4.48413944e-01 -9.83443022e-02]]\n",
      "joint_2d (243, 17, 2)\n",
      "confidence (243, 17, 1)\n",
      "camera_name (243,)\n",
      "action (243,)\n",
      "source (243,)\n",
      "frame (243,)\n",
      "cam_3d (243, 17, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((243, 17, 2), (2929, 17, 2))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_2ds = {'train': [], 'test': []}\n",
    "confidences = {'train': [], 'test': []}\n",
    "camera_names = {'train': [], 'test': []}\n",
    "actions = {'train': [], 'test': []}\n",
    "sources = {'train': [], 'test': []}\n",
    "frames = {'train': [], 'test': []}\n",
    "cam_3ds = {'train': [], 'test': []}\n",
    "\n",
    "# target \n",
    "only_test = True\n",
    "subject = '3dhp'\n",
    "data_type = 'test' \n",
    "\n",
    "print(test_data['pose2d'].shape, test_data['pose3d'].shape)\n",
    "# 16 joints -> 17 joints # nose -> 9\n",
    "new_pose2d, new_pose3d = add_nose_keypoint(test_data['pose2d'], test_data['pose3d'])\n",
    "\n",
    "joint_2ds[data_type] += list(new_pose2d) # \n",
    "confidences[data_type] += list(np.ones_like(new_pose2d[:, :, 0:1]))\n",
    "actions[data_type] += list([subject])*len(new_pose2d)\n",
    "sources[data_type] += list([subject])*len(new_pose2d)\n",
    "camera_names[data_type] += list([subject])*len(new_pose2d)\n",
    "frames[data_type] += [i for i in range(len(new_pose2d))]\n",
    "cam_3ds[data_type] += list(np.array(new_pose3d))\n",
    "print(cam_3ds[data_type][0])\n",
    "    \n",
    "data_total = {'train': {}, 'test': {}}\n",
    "\n",
    "for data_type in ['train', 'test']:\n",
    "    data_total[data_type]['joint_2d']          = copy.deepcopy(np.array(joint_2ds[data_type]))\n",
    "    data_total[data_type]['confidence']        = copy.deepcopy(np.array(confidences[data_type]))\n",
    "    data_total[data_type]['camera_name']       = copy.deepcopy(np.array(camera_names[data_type]))\n",
    "    data_total[data_type]['action']            = copy.deepcopy(np.array(actions[data_type]))\n",
    "    data_total[data_type]['source']            = copy.deepcopy(np.array(sources[data_type]))\n",
    "    data_total[data_type]['camera_name']       = copy.deepcopy(np.array(camera_names[data_type]))\n",
    "    data_total[data_type]['frame']             = copy.deepcopy(np.array(frames[data_type]))\n",
    "    data_total[data_type]['cam_3d']            = copy.deepcopy(np.array(cam_3ds[data_type]))\n",
    "\n",
    "\n",
    "if (len(data_total['train']['joint_2d']) == 0) or only_test:\n",
    "    for key in data_total['train'].keys():\n",
    "        data_total['train'][key] = copy.deepcopy(data_total['test'][key][:243])\n",
    "        print(key, data_total['train'][key].shape)\n",
    "data_total['train']['joint_2d'].shape, data_total['test']['joint_2d'].shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2929, 17, 2), (2929, 17, 1), (2929, 17, 3))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_total['test']['joint_2d'].shape, data_total['test']['confidence'].shape, data_total['test']['cam_3d'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('/home/hrai/codes/MotionBERT', f'data/motion3d/poseaug_3dhp_test.pkl')\n",
    "savepkl(data_total, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motionbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "a22adeb9c65037913f217d555eca4ee12416bb8cd04fc64921ca248554344da3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
