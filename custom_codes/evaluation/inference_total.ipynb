{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import os, sys, getpass\n",
    "user = getpass.getuser()\n",
    "sys.path.append(f'/home/{user}/codes/hpe_library')\n",
    "from hpe_library.lib_import import *\n",
    "from my_utils import BatchCamera, Camera\n",
    "from my_utils import arg_as_list, get_configs\n",
    "from my_utils import generate_random_segment, generate_random_trajectory, get_aligned_init_torso, get_ap_pose_2d, get_backbone_line_from_torso, get_bounded_segments_idx, get_cam_param, get_input, get_label, get_model_input, get_output, get_pairs, get_part_traj, get_pose_seq_and_cam_param, get_two_point_parts, load_h36m, load_segment_file_from_parameters, make_input, make_one_dimension_list, make_output, split_continuous_indices, MyCustomDataset, parse_args_by_model_name, get_input_gt_for_onevec, get_limb_angle, get_h36m_camera_info, h36m_data_processing\n",
    "from my_utils import DH_matrix, azim_elev_to_vec, batch_azim_elev_to_vec, batch_inverse_tf, batch_projection, batch_rot_x_matrix, batch_rot_y_matrix, batch_rot_z_matrix, calculate_azimuth_elevation, calculate_rotation_quaternion, draw_arm, draw_subline, draw_torso_direction, frame_vec_to_matrix, generate_batch_tf_from_batch_origin_R, generate_camera_frame, generate_dh_frame, generate_tf_from_origin_R, generate_two_link, generate_vis_frame, generate_world_frame, get_batch_frame_vec_from_keypoints, get_batch_lower_torso_frame_from_keypoints, get_batch_lower_torso_frame_from_pose, get_batch_reference_frame, get_batch_upper_torso_frame_from_keypoints, get_batch_upper_torso_frame_from_pose, get_frame_from_keypoints, get_lower_torso_frame_from_pose, get_reference_frame, get_torso_direction, get_torso_rotation_matrix, get_torso_shape, get_upper_torso_frame_from_pose, inverse_tf, normalize_vector, project_batch_tensor, projection, rotate_torso_by_R, rotate_torso_by_R_for_batch_tensor, rotation_matrix_to_vector_align, rotation_matrix_torso2torso, Appendage, BatchAppendage, BatchDHModel, DHModel, calculate_batch_azimuth_elevation\n",
    "from my_utils import args_dict_to_namespace, construct_torso_from_output, denormalize_motionbert_result, get_dataset_info_from_segment_folder, get_inference_from_dhdst, get_inference_from_dhdst_torso, get_inference_from_motionbert, get_output_type, get_result, infer_one_segment, load_best_model_for_inference, normalize_input, test_model_by_segment_file\n",
    "from my_utils import get_logger, log_configs\n",
    "from my_utils import init_weights, split_array_by_idxs, BaselineModel, Linear, TorsoModel\n",
    "from my_utils import Camera2ImageCoordinate, MPJPE, MPJPE_for_multiple_pose, MPJPE_for_single_pose, World2CameraCoordinate, World2ImageCoordinate, _sqrt_positive_part, _weak_project, aihub2h36m, array2dict, avgErrorForOneAction, avgErrorForOneActor, avgErrorForOneCamera, camera_to_image_frame, change_bbox_convention, check_max_min, coco2h36m, draw_skeleton, draw_skeleton_2d, draw_skeleton_both, euclidean_distance, fit3d2h36m, load_fit3d_one_video, getAIHubCameraParameter, getGT, getNumFromImgName, get_batch_h36m_keypoints, get_bbox_area, get_bbox_area_from_pose2d, get_bbox_from_pose2d, get_h36m_keypoint_index, get_h36m_keypoints, get_rootrel_pose, get_video_frame, get_video_info, get_xy_centered_pose, halpe2h36m, infer_box, kookmin2h36m, kookmin2h36m_with_nose, loadAIHubCameraParameter, matrix_to_quaternion, normalize, normalize_array, optimize_scaling_factor, plot_cv2_image, readJSON, readpkl, savepkl, skew_symmetric_matrix, skew_symmetric_matrix_tensor, standardize_quaternion, mpi_inf_3dhp2h36m, get_pose_height, get_batch_bbox_from_pose2d, get_h36m_limb_lens, part_ids, h36m_part_keypoints, get_h36m_limb_lens\n",
    "from my_utils import check_duplicate_training, get_input_output_candidate, get_num_trial, load_args, load_best_model, load_dataset, load_model, prepare_training, run, run_epoch, save_args, split_array_by_idxs\n",
    "from my_utils import axes_2d, axes_3d, axes_to_compare_pred_gt, draw_3d_pose, draw_bbox, draw_multiple_2d_pose, draw_multiple_3d_pose, draw_one_segment, draw_rotation_matrix, draw_segment, draw_segments, draw_trajectory, get_2d_pose_image, legend_without_duplicate_labels, plot_to_compare_pred_gt, save_h36m_pose_video, show2Dtrajectory, show3Dtrajectory, show_2d_3d, show_whole_segment_trajectories, draw_2d_pose, clear_axes\n",
    "from my_utils import check_available_frame, check_continuity, draw_base_marker_3d, generate_kookmin_pkl_for_each_video, get_cam_param_kookmin, get_video_frame_kookmin, get_video_num_frame_kookmin, load_pose3d_kookmin, load_csv_kookmin, get_lbot\n",
    "\n",
    "# 주요 디렉토리 경로\n",
    "user = getpass.getuser()\n",
    "alphapose_root = f'/home/{user}/codes/AlphaPose'\n",
    "motionbert_root = f'/home/{user}/codes/MotionBERT'\n",
    "kookmin_root = f'/home/{user}/Datasets/HAAI/국민대데이터/data'\n",
    "ap_kookmin_result_root = alphapose_root + \"/examples/kookmin_result_5actions\"\n",
    "\n",
    "assert os.path.isdir(alphapose_root), \"AlphaPose root directory is not exist\"\n",
    "assert os.path.isdir(motionbert_root), \"MotionBERT root directory is not exist\"\n",
    "#assert os.path.isdir(kookmin_root), \"Kookmin root directory is not exist\"\n",
    "#assert os.path.isdir(ap_kookmin_result_root), \"AlphaPose Kookmin result directory is not exist\"\n",
    "\n",
    "os.chdir(motionbert_root)\n",
    "from lib.utils.tools import * # get_config\n",
    "from lib.utils.learning import * # load_backbone\n",
    "from lib.utils.args import get_opts_args\n",
    "from lib.utils.utils_data import flip_data\n",
    "from lib.model.load_model import load_model\n",
    "from lib.model.load_dataset import load_dataset\n",
    "from lib.model.loss import *\n",
    "from lib.model.training import *\n",
    "from lib.model.evaluation import *\n",
    "from lib.data.datareader_kookmin import DataReaderKOOKMIN\n",
    "from lib.data.datareader_h36m import DataReaderH36M\n",
    "from lib.data.datareader_fit3d import DataReaderFIT3D\n",
    "from lib.data.datareader_random_limb import DataReaderRandomLimb\n",
    "from lib.data.dataset_motion_3d import MotionDataset3D\n",
    "from lib.model.DHDSTformer import DHDSTformer_total, DHDSTformer_total2, DHDSTformer_total3, DHDSTformer_total4, DHDSTformer_total5, DHDSTformer_total6, DHDSTformer_total7, DHDSTformer_total8, \\\n",
    "    DHDSTformer_limb, DHDSTformer_torso, DHDSTformer_torso2\n",
    "    \n",
    "dt_file_mapping = {\n",
    "    'H36M-GT': 'h36m_gt',\n",
    "    'H36M-GT-CAM_NO_FACTOR': 'h36m_gt',\n",
    "    'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_DIST': 'h36m_gt_canonical_3d_same_dist',\n",
    "    'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_DIST-S15678_TR_54138969_TS_OTHERS': 'h36m_gt_canonical_3d_same_dist_s15678_tr_54138969_ts_others',\n",
    "    'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_DIST-TR_S1_TS_S5678': 'h36m_gt_canonical_3d_same_dist_tr_s1_ts_s5678',\n",
    "    'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z': 'h36m_gt_canonical_3d_same_z',\n",
    "    'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678': 'h36m_gt_canonical_3d_same_z_tr_s1_ts_s5678',\n",
    "    'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678_BY_CANON1_6_PRED': 'h36m_gt_canonical_3d_same_z_tr_s1_ts_s5678',\n",
    "    'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678_BY_CANON2_2_PRED': 'h36m_gt_canonical_3d_same_z_tr_s1_ts_s5678',\n",
    "    'H36M-GT-CAM_NO_FACTOR-S15678_TR_54138969_TS_OTHERS': 'h36m_gt_s15678_tr_54138969_ts_others',\n",
    "    'H36M-GT-CAM_NO_FACTOR-TR_S1_TS_S5678': 'h36m_gt_tr_s1_ts_s5678',\n",
    "    'H36M-GT-INPUT_FROM_3D_CANONICAL_SAME_DIST-TR_S1_TS_S5678': 'h36m_gt_canonical_3d_same_dist_tr_s1_ts_s5678',\n",
    "    'H36M-GT-TR_S1_TS_S5678': 'h36m_gt_tr_s1_ts_s5678',\n",
    "    'H36M-GT-WORLD_NO_FACTOR': 'h36m_gt',\n",
    "    'H36M-SH': 'h36m_sh_conf_cam_source_final',\n",
    "    'H36M-CANONICALIZATION-GT-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678': 'h36m_gt_canonical_3d_same_z_tr_s1_ts_s5678',\n",
    "    'FIT3D-GT-ALL_TEST': 'fit3d_gt_all_test',\n",
    "    'FIT3D-GT-CAM_NO_FACTOR-ALL_TEST': 'fit3d_gt_all_test',\n",
    "    'FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-ALL_TEST': 'fit3d_gt_canonical_3d_same_z_all_test',\n",
    "    'FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S03': 'fit3d_gt_canonical_3d_same_z_tr_s03',\n",
    "    'FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TS_S4710': 'fit3d_gt_canonical_3d_same_z_ts_s4710',\n",
    "    'FIT3D-GT-CAM_NO_FACTOR-TS_S4710': 'fit3d_gt_ts_s4710',\n",
    "    'FIT3D-GT-TS_S4710': 'fit3d_gt_ts_s4710',\n",
    "    '3DHP-GT-CAM_NO_FACTOR-POSEAUG_TEST_2929': 'poseaug_3dhp_test',\n",
    "    '3DHP-GT-CAM_NO_FACTOR-POSYNDA_TESTSET': '3dhp_gt_test',\n",
    "    '3DHP-GT-CAM_NO_FACTOR-TEST_ALL_TRAIN': '3dhp_gt_test_all_train',\n",
    "    '3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN': '3dhp_gt_canonical_3d_same_z_test_all_train',\n",
    "    '3DHP-GT-CAM_NO_FACTOR-TEST_TS1_4': '3dhp_gt_test_TS1_4',\n",
    "    '3DHP-GT-CAM_NO_FACTOR-TEST_TS1_6': '3dhp_gt_test_TS1_6',\n",
    "    '3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_4': '3dhp_gt_test_canonical_3d_from_same_z_TS1_4',\n",
    "    '3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6': '3dhp_gt_test_canonical_3d_from_same_z_TS1_6',\n",
    "    'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5': 'h36m_gt_canonical_3d_fixed_dist_5',\n",
    "    'H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TR_S1_TS_S5678': 'h36m_gt_canonical_3d_fixed_dist_5_tr_s1_ts_s5678',\n",
    "    'FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-ALL_TEST': 'fit3d_gt_canonical_3d_fixed_dist_5_all_test',\n",
    "    '3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TEST_TS1_6': '3dhp_gt_test_canonical_3d_from_fixed_dist_5_TS1_6',\n",
    "    '3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TEST_ALL_TRAIN': '3dhp_gt_canonical_3d_fixed_dist_5_test_all_train'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages: 203\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Notion API 키 및 데이터베이스 ID 설정\n",
    "notion = readpkl('notion.pkl')\n",
    "NOTION_API_KEY = notion['NOTION_API_KEY']\n",
    "DATABASE_ID = notion['DATABASE_ID']\n",
    "\n",
    "# 헤더 설정\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {NOTION_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Notion-Version\": \"2022-06-28\"\n",
    "}\n",
    "\n",
    "def get_all_database_pages():\n",
    "    url = f\"https://api.notion.com/v1/databases/{DATABASE_ID}/query\"\n",
    "    all_pages = []\n",
    "    has_more = True\n",
    "    start_cursor = None\n",
    "    \n",
    "    while has_more:\n",
    "        if start_cursor:\n",
    "            data = {\"start_cursor\": start_cursor}\n",
    "        else:\n",
    "            data = {}\n",
    "        \n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response_data = response.json()\n",
    "        \n",
    "        all_pages.extend(response_data[\"results\"])\n",
    "        has_more = response_data.get(\"has_more\", False)\n",
    "        start_cursor = response_data.get(\"next_cursor\", None)\n",
    "    print(f\"Total pages: {len(all_pages)}\")\n",
    "    return all_pages\n",
    "\n",
    "pages = get_all_database_pages()\n",
    "\n",
    "pages_dict = {}\n",
    "for page in pages:\n",
    "    pages_dict[page[\"id\"]] = page\n",
    "    \n",
    "model_dict = {}\n",
    "for page in pages:\n",
    "    page_id = page[\"id\"]\n",
    "    property = page[\"properties\"]\n",
    "    try:\n",
    "        model_name = property[\"Model\"]['select']['name']\n",
    "    except: continue\n",
    "    if model_name not in model_dict:\n",
    "        model_dict[model_name] = []\n",
    "    model_dict[model_name].append(page_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list_pose3d = [item.split('.')[0] for item in os.listdir('/home/hrai/codes/MotionBERT/configs/pose3d')]\n",
    "# filtering\n",
    "blacklist = ['world', 'ft']\n",
    "mustbe = ['MB', 'gt']\n",
    "for item in experiment_list_pose3d:\n",
    "    for keyword in blacklist:\n",
    "        if keyword in item:\n",
    "            experiment_list_pose3d.remove(item)\n",
    "    if item not in experiment_list_pose3d: continue\n",
    "    for keyword in mustbe:\n",
    "        if keyword not in item:\n",
    "            experiment_list_pose3d.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB_train_h36m_gt\n",
      "   FIT3D-GT-ALL_TEST\n",
      "   H36M-GT\n",
      "MB_train_fit3d_gt_cam_no_factor_input_from_canonical_3d_same_z_input_centering_ts_s4710\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "   FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TS_S4710\n",
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z_input_centering\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6\n",
      "   FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-ALL_TEST\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "MB_train_h36m_gt_with_canonical2\n",
      "   FIT3D-GT-ALL_TEST\n",
      "   H36M-GT\n",
      "MB_train_h36m_gt_cam_no_factor\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_TS1_6\n",
      "   FIT3D-GT-CAM_NO_FACTOR-ALL_TEST\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_ALL_TRAIN\n",
      "   H36M-GT-CAM_NO_FACTOR\n",
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z_s15678_tr_54138969_ts_others\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-S15678_TR_54138969_TS_OTHERS\n",
      "MB_train_fit3d_gt_cam_no_factor_input_from_canonical_3d_same_z_tr_s03\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "   FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S03\n",
      "MB_train_h36m_gt_cam_no_factor_with_canonical2_norm_input_scale\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_TS1_6\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_ALL_TRAIN\n",
      "   FIT3D-GT-CAM_NO_FACTOR-ALL_TEST\n",
      "   H36M-GT-CAM_NO_FACTOR\n",
      "MB_train_fit3d_gt_cam_no_factor_input_from_canonical_3d_same_z_input_centering_tr_s03\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678\n",
      "   FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S03\n",
      "MB_train_h36m_gt_with_canonical2_tr_s1_ts_s5678\n",
      "   H36M-GT\n",
      "   FIT3D-GT-ALL_TEST\n",
      "   H36M-GT-TR_S1_TS_S5678\n",
      "MB_train_h36m_gt_cam_no_factor_s15678_tr_54138969_ts_others\n",
      "   H36M-GT-CAM_NO_FACTOR-S15678_TR_54138969_TS_OTHERS\n",
      "MB_train_h36m_gt_cam_no_factor_tr_s1_ts_s5678\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_TS1_6\n",
      "   H36M-GT-CAM_NO_FACTOR\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_ALL_TRAIN\n",
      "   FIT3D-GT-CAM_NO_FACTOR-ALL_TEST\n",
      "   H36M-GT-CAM_NO_FACTOR-TR_S1_TS_S5678\n",
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_fixed_dist_5_input_centering_tr_s1_ts_s5678\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TEST_ALL_TRAIN\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TEST_TS1_6\n",
      "   FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-ALL_TEST\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TR_S1_TS_S5678\n",
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z_tr_s1_ts_s5678\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "   FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-ALL_TEST\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678\n",
      "MB_train_h36m_gt_cam_no_factor_with_canonical2\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_TS1_6\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_ALL_TRAIN\n",
      "   FIT3D-GT-CAM_NO_FACTOR-ALL_TEST\n",
      "   H36M-GT-CAM_NO_FACTOR\n",
      "MB_train_fit3d_gt_cam_no_factor_with_canonical2_ts_s4710\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_TS1_6\n",
      "   H36M-GT-CAM_NO_FACTOR\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_ALL_TRAIN\n",
      "   H36M-GT-CAM_NO_FACTOR-TR_S1_TS_S5678\n",
      "   FIT3D-GT-CAM_NO_FACTOR-TS_S4710\n",
      "MB_train_fit3d_gt_cam_no_factor_ts_s4710\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_TS1_6\n",
      "   H36M-GT-CAM_NO_FACTOR\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_ALL_TRAIN\n",
      "   H36M-GT-CAM_NO_FACTOR-TR_S1_TS_S5678\n",
      "   FIT3D-GT-CAM_NO_FACTOR-TS_S4710\n",
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z_input_centering_tr_s1_ts_s5678\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "   FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-ALL_TEST\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678\n",
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6\n",
      "   FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-ALL_TEST\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "MB_train_fit3d_gt_cam_no_factor_input_from_canonical_3d_same_z_ts_s4710\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678\n",
      "   FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TS_S4710\n",
      "MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_fixed_dist_5_input_centering\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TEST_ALL_TRAIN\n",
      "   3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TEST_TS1_6\n",
      "   FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-ALL_TEST\n",
      "   H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5\n",
      "MB_train_fit3d_gt_ts_s4710\n",
      "   H36M-GT\n",
      "   H36M-GT-TR_S1_TS_S5678\n",
      "   FIT3D-GT-TS_S4710\n",
      "MB_train_fit3d_gt_cam_no_factor_tr_s03\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_ALL_TRAIN\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_TS1_6\n",
      "   H36M-GT-CAM_NO_FACTOR-TR_S1_TS_S5678\n",
      "   H36M-GT-CAM_NO_FACTOR\n",
      "   FIT3D-GT-CAM_NO_FACTOR-TR_S03\n",
      "MB_train_h36m_gt_cam_no_factor_with_canonical2_tr_s1_ts_s5678\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_TS1_6\n",
      "   H36M-GT-CAM_NO_FACTOR\n",
      "   3DHP-GT-CAM_NO_FACTOR-TEST_ALL_TRAIN\n",
      "   FIT3D-GT-CAM_NO_FACTOR-ALL_TEST\n",
      "   H36M-GT-CAM_NO_FACTOR-TR_S1_TS_S5678\n",
      "MB_train_h36m_gt_tr_s1_ts_s5678\n",
      "   H36M-GT\n",
      "   FIT3D-GT-ALL_TEST\n",
      "   H36M-GT-TR_S1_TS_S5678\n",
      "MB_train_fit3d_gt_with_canonical2_ts_s4710\n",
      "   H36M-GT\n",
      "   H36M-GT-TR_S1_TS_S5678\n",
      "   FIT3D-GT-TS_S4710\n"
     ]
    }
   ],
   "source": [
    "# get test list from notion\n",
    "root = '/home/hrai/codes/MotionBERT/experiments'\n",
    "if not os.path.isdir(root): os.makedirs(root)\n",
    "blacklist_keyword = ['PRED', 'POSEAUG', 'posynda', 'TS1_4']\n",
    "\n",
    "for key in experiment_list_pose3d:\n",
    "    if key not in model_dict: continue\n",
    "    if 'dist' in key: \n",
    "        if 'fixed_dist_5' in key:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "    model_ids = model_dict[key]\n",
    "    file_path = os.path.join(root, key + '.txt') \n",
    "    print(key)\n",
    "    with open(file_path, 'w') as file:\n",
    "        for model_id in model_ids:\n",
    "            page = pages_dict[model_id]\n",
    "            train = page['properties']['Train dataset']['select'] \n",
    "            test = page['properties']['Test dataset']['select']\n",
    "            # filtering - parent\n",
    "            if test == None: continue # parent\n",
    "            \n",
    "            # get child page's info\n",
    "            child_page = pages_dict[model_id]\n",
    "            child_properties = child_page['properties']\n",
    "            if len(child_properties['Name']['title']) == 0: continue\n",
    "            child_title = child_properties['Name']['title'][0]['text']['content']\n",
    "            child_canonical = child_properties['Canonical']['multi_select']\n",
    "            \n",
    "            # filtering - keyword\n",
    "            black = False\n",
    "            for keyword in blacklist_keyword:\n",
    "                if keyword in child_title: black = True\n",
    "            if black: continue\n",
    "            \n",
    "            # filtering - input_centering_only_test\n",
    "            input_centering_only_test = False\n",
    "            for item in child_canonical:\n",
    "                if 'only test' in item['name']:\n",
    "                    input_centering_only_test = True\n",
    "            if input_centering_only_test: continue\n",
    "            \n",
    "            # write to txt file\n",
    "            print('  ', child_title)\n",
    "            file.writelines(child_title+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z]\n",
      "3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN\n",
      "  3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN already exists. Skip.\n",
      "3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6\n",
      "  3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6 already exists. Skip.\n",
      "FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-ALL_TEST\n",
      "  FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-ALL_TEST already exists. Skip.\n",
      "H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "  H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z already exists. Skip.\n",
      "[MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_same_z_input_centering_tr_s1_ts_s5678]\n",
      "3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN\n",
      "  3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_ALL_TRAIN already exists. Skip.\n",
      "3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6\n",
      "  3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TEST_TS1_6 already exists. Skip.\n",
      "H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z\n",
      "  H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z already exists. Skip.\n",
      "FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-ALL_TEST\n",
      "  FIT3D-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-ALL_TEST already exists. Skip.\n",
      "H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678\n",
      "  H36M-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_SAME_Z-TR_S1_TS_S5678 already exists. Skip.\n",
      "[MB_train_h36m_gt_cam_no_factor_input_from_canonical_3d_fixed_dist_5_input_centering_tr_s1_ts_s5678]\n",
      "3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TEST_ALL_TRAIN\n",
      "   cam_3d True 3dhp_gt_canonical_3d_fixed_dist_5_test_all_train.pkl\n",
      "Loading dataset...\n",
      "3DHP-GT-CAM_NO_FACTOR-INPUT_FROM_3D_CANONICAL_FIXED_DIST_5-TEST_ALL_TRAIN\n",
      "3DHP\n",
      "INFO: Testing\n",
      "No epoch information in the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/245 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/hrai/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/hrai/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/hrai/codes/MotionBERT/lib/model/DSTformer.py\", line 338, in forward\n    x = self.joints_embed(x) # feature embedding - (BxF, 17, 3) -> (BxF, 17, 256)\n  File \"/home/hrai/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/hrai/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (33048x4 and 3x512)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m'\u001b[39m, args\u001b[38;5;241m.\u001b[39mgt_mode, args\u001b[38;5;241m.\u001b[39mcanonical, args\u001b[38;5;241m.\u001b[39mdt_file)\n\u001b[1;32m     37\u001b[0m train_loader_3d, test_loader, posetrack_loader_2d, instav_loader_2d, datareader \u001b[38;5;241m=\u001b[39m load_dataset(args)\n\u001b[0;32m---> 39\u001b[0m e1, e2, results_all, inputs_all, gts_all, total_result_dict \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatareader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_one_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_result_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: total_result_dict}\n\u001b[1;32m     41\u001b[0m savepkl(results_dict, result_path)\n",
      "File \u001b[0;32m~/codes/MotionBERT/lib/model/evaluation.py:23\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(args, model_pos, test_loader, datareader, checkpoint, only_one_batch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo epoch information in the checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# get inference results          \u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m results_all, inputs_all, gts_all \u001b[38;5;241m=\u001b[39m \u001b[43minference_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatareader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_one_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# calculate evaluation metric\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCANONICALIZATION\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39msubset_list[\u001b[38;5;241m0\u001b[39m]: \u001b[38;5;66;03m# for canonicalization network\u001b[39;00m\n",
      "File \u001b[0;32m~/codes/MotionBERT/lib/model/evaluation.py:121\u001b[0m, in \u001b[0;36minference_eval\u001b[0;34m(args, model_pos, test_loader, datareader, only_one_batch)\u001b[0m\n\u001b[1;32m    119\u001b[0m batch_input, batch_gt, batch_gt_torso, batch_gt_limb_pos \u001b[38;5;241m=\u001b[39m preprocess_eval(args, batch_input, batch_gt)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# inference\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m predicted_3d_pos \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_inference_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_gt_torso\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_gt_limb_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# postprocessing\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mrootrel:\n",
      "File \u001b[0;32m~/codes/MotionBERT/lib/model/evaluation.py:89\u001b[0m, in \u001b[0;36mbatch_inference_eval\u001b[0;34m(args, model_pos, batch_input, batch_gt_torso, batch_gt_limb_pos)\u001b[0m\n\u001b[1;32m     87\u001b[0m     pred_torso \u001b[38;5;241m=\u001b[39m (pred_torso_1\u001b[38;5;241m+\u001b[39mpred_torso_2) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     predicted_3d_pos_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     predicted_3d_pos_flip \u001b[38;5;241m=\u001b[39m model_pos(batch_input_flip)\n\u001b[1;32m     91\u001b[0m     predicted_3d_pos_2 \u001b[38;5;241m=\u001b[39m flip_data(predicted_3d_pos_flip)                   \u001b[38;5;66;03m# Flip back\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/hrai/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/hrai/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/hrai/codes/MotionBERT/lib/model/DSTformer.py\", line 338, in forward\n    x = self.joints_embed(x) # feature embedding - (BxF, 17, 3) -> (BxF, 17, 256)\n  File \"/home/hrai/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/hrai/miniconda3/envs/motionbert/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (33048x4 and 3x512)\n"
     ]
    }
   ],
   "source": [
    "root = f'/home/{user}/codes/MotionBERT/experiments'\n",
    "config_root = 'configs/pose3d/'\n",
    "checkpoint_root = 'checkpoint/pose3d/'\n",
    "result_root = f'/home/{user}/codes/MotionBERT/custom_codes/evaluation/experiment_results'\n",
    "if not os.path.isdir(result_root): os.makedirs(result_root)\n",
    "\n",
    "#pbar = tqdm(glob(root+'/*.txt'))\n",
    "for item in glob(root+'/*.txt'):\n",
    "    model_name = os.path.basename(item).split('.')[0]\n",
    "    print(f'[{model_name}]')\n",
    "    config = model_name + '.yaml'\n",
    "    input_args = ['--config', config_root+config, '--evaluate', checkpoint_root+model_name+'/best_epoch.bin']\n",
    "    args, opts = get_opts_args(input_args, verbose=False)\n",
    "    args.print_summary_table = False\n",
    "    #print(args)\n",
    "    try:\n",
    "        model_pos, chk_filename, checkpoint = load_model(opts, args, verbose=False)\n",
    "    except:\n",
    "        print('  ', 'Failed to load model')\n",
    "        continue\n",
    "    \n",
    "    with open(item, 'r') as file:\n",
    "        for line in file:\n",
    "            subset = line.strip()\n",
    "            print(subset)\n",
    "            result_path = os.path.join(result_root, model_name+'/'+subset+'.pkl')\n",
    "            if os.path.exists(result_path): \n",
    "                print(f'  {subset} already exists. Skip.')\n",
    "                continue\n",
    "            args.subset_list = [subset]\n",
    "            try:\n",
    "                args.dt_file = dt_file_mapping[args.subset_list[0]]+'.pkl'\n",
    "            except:\n",
    "                print('  Not found in dt_file_mapping')\n",
    "                continue\n",
    "            print('  ', args.gt_mode, args.canonical, args.dt_file)\n",
    "            train_loader_3d, test_loader, posetrack_loader_2d, instav_loader_2d, datareader = load_dataset(args)\n",
    "\n",
    "            e1, e2, results_all, inputs_all, gts_all, total_result_dict = evaluate(args, model_pos, test_loader, datareader, checkpoint, only_one_batch=False)\n",
    "            results_dict = {'total_result_dict': total_result_dict}\n",
    "            savepkl(results_dict, result_path)\n",
    "            \n",
    "            del train_loader_3d, test_loader, posetrack_loader_2d, instav_loader_2d, datareader\n",
    "            \n",
    "    #pbar.set_postfix({'checkpoint': model_name})\n",
    "    del model_pos, chk_filename, checkpoint, \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = '/home/hrai/codes/MotionBERT/experiments'\n",
    "# if not os.path.isdir(root): os.makedirs(root)\n",
    "\n",
    "# sort_by_dataset = {}\n",
    "\n",
    "# for item in glob(root+'/*.txt'):\n",
    "#     model_name = os.path.basename(item).split('.')[0]\n",
    "#     with open(item, 'r') as file:\n",
    "#         for line in file:\n",
    "#             subset = line.strip()\n",
    "#             if subset not in sort_by_dataset:\n",
    "#                 sort_by_dataset[subset] = [model_name]\n",
    "#             else:\n",
    "#                 sort_by_dataset[subset].append(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motionbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a22adeb9c65037913f217d555eca4ee12416bb8cd04fc64921ca248554344da3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
