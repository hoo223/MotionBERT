{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Skeleton Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact\n",
    "import copy\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from test_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "motionbert_root = \"/home/hrai/codes/MotionBERT\"\n",
    "mb_output_root = motionbert_root + \"/output\"\n",
    "mb_aihub_output_root = mb_output_root + \"/aihub_30\"\n",
    "assert os.path.exists(mb_aihub_output_root) == True # check if the path exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_id(action):\n",
    "    for key in action_dict.keys():\n",
    "        if action_dict[key] == action:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MotionBERT_30_M160A_3\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "action_dict = {\n",
    "    '23' : \"BenchPress\",\n",
    "    '30' : \"Squat\",\n",
    "    '33' : \"Push_Up\",\n",
    "    '49' : \"Butterfly\"\n",
    "}\n",
    "\n",
    "for video in os.listdir(mb_aihub_output_root):\n",
    "    print(video)\n",
    "    _, action_id, actor, cam_id = video.split('_')\n",
    "    if action_id in action_dict.keys():\n",
    "        if action_dict[action_id] not in dataset.keys():\n",
    "            dataset[action_dict[action_id]] = {actor: {cam_id: {'output_path': os.path.join(mb_aihub_output_root, video)}}}\n",
    "        else:\n",
    "            if actor not in dataset[action_dict[action_id]].keys():\n",
    "                dataset[action_dict[action_id]][actor] = {cam_id: {'output_path': os.path.join(mb_aihub_output_root, video)}}\n",
    "            else:\n",
    "                if cam_id not in dataset[action_dict[action_id]][actor].keys():\n",
    "                    dataset[action_dict[action_id]][actor][cam_id] = {'output_path': os.path.join(mb_aihub_output_root, video)}\n",
    "                else:\n",
    "                    print(\"Video {} is already in dataset\".format(video))\n",
    "    else:\n",
    "        print(\"Action ID {} is not in action_dict\".format(action_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_path': '/home/hrai/codes/MotionBERT/output/aihub_30/MotionBERT_30_M160A_3'}\n",
      "(144, 17, 3)\n"
     ]
    }
   ],
   "source": [
    "for action in dataset.keys():\n",
    "    for actor in dataset[action].keys():\n",
    "        for cam_num in dataset[action][actor].keys():\n",
    "            print(dataset[action][actor][cam_num])\n",
    "            output_path = dataset[action][actor][cam_num]['output_path']\n",
    "            mp4, npy = os.listdir(output_path)\n",
    "            assert 'mp4' in mp4 # check if mp4 file exists\n",
    "            assert 'npy' in npy # check if npy file exists\n",
    "            output = np.load(os.path.join(output_path, npy))\n",
    "            print(output.shape)\n",
    "            dataset[action][actor][cam_num]['output'] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Squat': {'M160A': {'3': {'output_path': '/home/hrai/codes/MotionBERT/output/aihub_30/MotionBERT_30_M160A_3',\n",
       "    'output': array([[[ 1.70216372e-04,  3.55981640e-04,  0.00000000e+00],\n",
       "            [ 1.06207982e-01,  1.21679269e-02, -5.88868968e-02],\n",
       "            [ 7.93617517e-02,  4.58368808e-01,  7.30124116e-02],\n",
       "            ...,\n",
       "            [ 1.61644265e-01, -6.06383204e-01, -1.93266660e-01],\n",
       "            [ 2.45332122e-01, -2.42874220e-01, -1.65020734e-01],\n",
       "            [ 2.79138982e-01,  1.93081684e-02, -7.88548514e-02]],\n",
       "    \n",
       "           [[ 1.77083100e-04,  3.36375437e-04,  1.71567686e-03],\n",
       "            [ 1.06296457e-01,  1.21887997e-02, -5.89347221e-02],\n",
       "            [ 7.95113966e-02,  4.56995338e-01,  7.26836920e-02],\n",
       "            ...,\n",
       "            [ 1.61761433e-01, -6.06790602e-01, -1.93121448e-01],\n",
       "            [ 2.45349795e-01, -2.43140787e-01, -1.64609149e-01],\n",
       "            [ 2.78788477e-01,  1.94656923e-02, -7.89625049e-02]],\n",
       "    \n",
       "           [[ 1.35206268e-04,  3.33484611e-04,  1.75126572e-03],\n",
       "            [ 1.06215030e-01,  1.22979432e-02, -5.90701103e-02],\n",
       "            [ 7.88709894e-02,  4.55991924e-01,  7.22422600e-02],\n",
       "            ...,\n",
       "            [ 1.61405325e-01, -6.06812119e-01, -1.92880854e-01],\n",
       "            [ 2.44915456e-01, -2.43507475e-01, -1.64525867e-01],\n",
       "            [ 2.77874917e-01,  1.95953436e-02, -7.93094411e-02]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-5.45199541e-03,  4.08630306e-03, -3.98373511e-03],\n",
       "            [ 8.21010545e-02,  4.13843840e-02, -8.54604393e-02],\n",
       "            [ 5.43949962e-01, -1.72680989e-02,  1.16050184e-01],\n",
       "            ...,\n",
       "            [ 4.16436225e-01, -5.17409444e-01, -2.90747397e-02],\n",
       "            [ 6.65888548e-01, -5.34245133e-01, -2.08679829e-02],\n",
       "            [ 8.44118118e-01, -6.14329576e-01, -1.94163267e-02]],\n",
       "    \n",
       "           [[-6.49301335e-03,  3.22702946e-03, -5.10810642e-03],\n",
       "            [ 8.27842876e-02,  4.04269919e-02, -8.61891359e-02],\n",
       "            [ 5.45896292e-01, -2.59846076e-02,  1.16163790e-01],\n",
       "            ...,\n",
       "            [ 4.16903317e-01, -5.16655266e-01, -2.84162685e-02],\n",
       "            [ 6.65568590e-01, -5.32762229e-01, -1.77993067e-02],\n",
       "            [ 8.44147265e-01, -6.11208797e-01, -1.66540556e-02]],\n",
       "    \n",
       "           [[-6.75688405e-03,  3.56183806e-03, -4.50735027e-03],\n",
       "            [ 8.20621252e-02,  4.16540094e-02, -8.63668546e-02],\n",
       "            [ 5.46313465e-01, -2.73348577e-02,  1.15802847e-01],\n",
       "            ...,\n",
       "            [ 4.16337013e-01, -5.12513161e-01, -2.86876224e-02],\n",
       "            [ 6.64730728e-01, -5.26174068e-01, -1.65237542e-02],\n",
       "            [ 8.45372677e-01, -6.03282809e-01, -1.54724214e-02]]],\n",
       "          dtype=float32)}}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize 3D pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "plt.switch_backend('TkAgg')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 'Squat'\n",
    "actor = 'M160A'\n",
    "cam_num = '3'\n",
    "frame_num = 0\n",
    "pred = dataset[action][actor][cam_num]['output'][frame_num] # 3D pose of the first frame\n",
    "pred_hat = get_rootrel_pose(pred)\n",
    "\n",
    "fig = plt.figure(0, figsize=(10, 10))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.set_xlim(-512, 512)\n",
    "ax.set_ylim(-512, 512)\n",
    "ax.set_zlim(-512, 512)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.view_init(elev=12., azim=80)\n",
    "show3Dpose(pred_hat, ax)\n",
    "#plt.savefig('mb_result_{}_{}_{}_{}.png'.format(get_action_id(action), actor, cam_num, frame_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hrai/Datasets/HAAI/AIHUB/label/train/[라벨]3D_json.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aihub_root = \"/home/hrai/Datasets/HAAI/AIHUB\"\n",
    "aihub_3d_gt_path = os.path.join(aihub_root, \"label/train/[라벨]3D_json.zip\")\n",
    "aihub_3d_gt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load zip file\n",
    "zip_label = ZipFile(os.path.join(aihub_3d_gt_path), 'r')\n",
    "list_input = zip_label.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = '30'\n",
    "actor = 'M160A'\n",
    "frame = '30'\n",
    "# actor = 'M180D' #'M160A'\n",
    "# frame = '311' # '30'\n",
    "load_path = \"3D_json/{}_{}/3D_{}_{}_{}.json\".format(action, actor, action, actor, frame)\n",
    "gt = json.loads(zip_label.read(load_path).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'annotations'])\n",
      "dict_keys(['supercategory', 'action_category_id', 'actor_id', '3d_pos', '3d_rot'])\n",
      "dict_keys(['frame_no', 'obj_path', '3d_pos', '3d_rot', 'trans_params'])\n"
     ]
    }
   ],
   "source": [
    "print(gt.keys())\n",
    "print(gt['info'].keys())\n",
    "print(gt['annotations'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load camera parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_camera_param_path = os.path.join(aihub_root, \"label/train/Camera_json_train.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load zip file\n",
    "zip_param = ZipFile(os.path.join(aihub_camera_param_path), 'r')\n",
    "list_input = zip_param.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = '30'\n",
    "# #actor = 'M180D' \n",
    "# cam_num = '4'\n",
    "actor = 'M160A'\n",
    "cam_num = '3'\n",
    "load_path = \"Camera_json/train/{}_{}_{}.json\".format(action, actor, cam_num)\n",
    "camera_param = json.loads(zip_param.read(load_path).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'camera_date': '20201008',\n",
       " 'camera_no': 3,\n",
       " 'extrinsics': [[-0.733395875, 0.026952436, 0.679267645, -8.36987305],\n",
       "  [-0.155711249, -0.979308605, -0.129261598, 740.389099],\n",
       "  [0.66172874, -0.200569466, 0.722417653, 4432.7334]],\n",
       " 'intrinsics': [[0.68166077, 0.0, 0.50988585],\n",
       "  [0.0, 0.68166077, 0.26416245],\n",
       "  [0.0, 0.0, 1.0]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 1920\n",
    "H = 1080\n",
    "extrinsic_properties = np.array(camera_param['extrinsics'])\n",
    "R = copy.deepcopy(np.array(camera_param['extrinsics'])[:,:3])\n",
    "T = copy.deepcopy(np.array(camera_param['extrinsics'])[:,3])\n",
    "R_c = R.T\n",
    "C = - np.matmul(R_c, T)\n",
    "intrinsic_properties = np.array(camera_param['intrinsics']) # normalized intrinsic matrix\n",
    "intrinsic_properties[:2, :] *= W # denormalize\n",
    "fx = intrinsic_properties[0,0]\n",
    "fy = intrinsic_properties[1,1]\n",
    "cx = intrinsic_properties[0,2]\n",
    "cy = intrinsic_properties[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aihub to h36m pose\n",
    "world_3d = aihub2h36m(np.array(gt['annotations']['3d_pos'])[:, :3].reshape(1, 24, 3))[0]\n",
    "world_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(0, figsize=(10, 10))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "min_, max_ = -2000, 2000\n",
    "ax.set_xlim(min_, max_)\n",
    "ax.set_ylim(min_, max_)\n",
    "ax.set_zlim(min_, max_)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.view_init(elev=12., azim=80)\n",
    "show3Dpose(world_3d, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate scaling factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world to camera\n",
    "pos = copy.deepcopy(world_3d)\n",
    "cam_3d = World2CameraCoordinate(pos, extrinsic_properties) # World coordinate -> Camera coordinate\n",
    "cam_3d_hat = get_rootrel_pose(cam_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(0, figsize=(10, 10))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "min_, max_ = -2000, 2000\n",
    "ax.set_xlim(min_, max_)\n",
    "ax.set_ylim(min_, max_)\n",
    "ax.set_zlim(min_, max_)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.view_init(elev=12., azim=80)\n",
    "show3Dpose(cam_3d_hat, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera to image\n",
    "box = infer_box(cam_3d, {'fx': fx, 'fy': fy, 'cx': cx, 'cy': cy}, 0)\n",
    "img_2d, img_3d = camera_to_image_frame(cam_3d, box, {'fx': fx, 'fy': fy, 'cx': cx, 'cy': cy}, 0) \n",
    "img_2d_hat = get_rootrel_pose(img_2d) # (17, 2) # root-relative pose \n",
    "img_3d_hat = get_rootrel_pose(img_3d) # (17, 3) # root-relative pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize 2D pose\n",
    "img_path = \"/home/hrai/Datasets/HAAI/AIHUB/30_M160A_3/30_M160A_3_30.jpg\"\n",
    "#img_path = \"/home/hrai/Datasets/HAAI/AIHUB/30_M180D_4/30_M180D_4_311.jpg\"\n",
    "#img = np.ones([1080, 1920, 3])\n",
    "img = cv2.imread(img_path)\n",
    "img = get_2d_pose_image(img_2d, img, box)\n",
    "plot_cv2_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "# img_2d\n",
    "img = np.ones([2000, 2000, 3])\n",
    "img = get_2d_pose_image(cam_3d_hat[:, :2] + 1000, img)\n",
    "plot_cv2_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3579845428466797"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimize scaling factor\n",
    "pred_lambda, losses = optimize_scaling_factor(img_3d_hat, cam_3d_hat) # x,y,z 사용\n",
    "pred_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_25d = img_3d * pred_lambda\n",
    "img_25d_hat = get_rootrel_pose(img_25d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(0, figsize=(10, 10))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.set_xlim(-512, 512)\n",
    "ax.set_ylim(-512, 512)\n",
    "ax.set_zlim(-512, 512)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.view_init(elev=12., azim=80)\n",
    "\n",
    "show3Dpose(img_25d_hat, ax)\n",
    "show3Dpose(cam_3d_hat, ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize inference and gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hat_scaled = pred_hat * pred_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(0, figsize=(10, 10))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.set_xlim(-512, 512)\n",
    "ax.set_ylim(-512, 512)\n",
    "ax.set_zlim(-512, 512)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.view_init(elev=12., azim=80)\n",
    "\n",
    "show3Dpose(img_25d_hat, ax)\n",
    "show3Dpose(pred_hat*1000,  ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MPJPE for single pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from test_utils import MPJPE_for_single_pose, MPJPE_for_multiple_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.47767607231927 mm\n"
     ]
    }
   ],
   "source": [
    "mpjpe = MPJPE_for_single_pose(img_25d_hat, cam_3d_hat)\n",
    "print(mpjpe, \"mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421.74566232806006 mm\n"
     ]
    }
   ],
   "source": [
    "mpjpe = MPJPE_for_single_pose(img_25d_hat, pred_hat_scaled)\n",
    "print(mpjpe, \"mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For multiple frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 M160A 3\n",
      "3D_json/30_M160A/3D_30_M160A_30.json\n"
     ]
    }
   ],
   "source": [
    "# whitelist\n",
    "action_list = ['30']\n",
    "actor_list = ['M160A']\n",
    "frame_list = ['30']\n",
    "\n",
    "#list_input = zip_label.namelist()\n",
    "for action in action_list:\n",
    "    for actor in actor_list:\n",
    "        for frame in frame_list:\n",
    "            print(action, actor, cam_num)\n",
    "            load_path = \"3D_json/{}_{}/3D_{}_{}_{}.json\".format(action, actor, action, actor, frame)\n",
    "            print(load_path)\n",
    "            data_label = json.loads(zip_label.read(load_path).decode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motionbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "996031ba2a0f3c1298a339c0299835a7fe1ef636d9e79358bc474ca43ed2ac18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
