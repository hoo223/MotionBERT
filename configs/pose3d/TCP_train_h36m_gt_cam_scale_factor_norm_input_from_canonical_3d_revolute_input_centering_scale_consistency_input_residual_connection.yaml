# General
train_2d: False
no_eval: False
finetune: False
partial_train: null
input_centering: True
fix_orientation_pred: False
scale_consistency: True
input_residual_connection: True
test_run: False

# Traning
epochs: 90
checkpoint_frequency: 30
batch_size: 4
dropout: 0.0
learning_rate: 0.0005
weight_decay: 0.01
lr_decay: 0.99

# Test
part_list: ['whole']
denormalize_output: False

# Model
model: 'TCP_train_h36m_gt_cam_scale_factor_norm_input_from_canonical_3d_revolute_input_centering_scale_consistency_input_residual_connection'
backbone: 'TCPFormer'
n_layers: 16
dim_in: 3
dim_feat: 128
dim_rep: 512
dim_out: 3
mlp_ratio: 4
act_layer: gelu
attn_drop: 0.0
drop: 0.0
drop_path: 0.0
use_layer_scale: True
layer_scale_init_value: 0.00001
use_adaptive_fusion: True
num_heads: 8
qkv_bias: False
qkv_scale: null
hierarchical: False
use_temporal_similarity: True 
neighbour_num: 2  
temporal_connection_len: 1 
use_tcn: False
graph_only: False
n_frames: 243 

maxlen: 243
# dim_feat: 512
# mlp_ratio: 2
# depth: 5
# dim_rep: 512
# num_heads: 8
# att_fuse: True

# Data
data_root: data/motion3d/MB3D_f243s81/
subset_list: [H36M-GT-CAM_SCALE_FACTOR_NORM-INPUT_FROM_3D_CANONICAL_REVOLUTE]
clip_len: 243
data_stride: 81
rootrel: True
sample_stride: 1
num_joints: 17
no_conf: False
gt_2d: False
input_mode: 'joint_2d_from_canonical_3d'
gt_mode: 'img_3d_norm_canonical'
mpjpe_mode: 'cam_3d_from_canonical_3d'

# Loss
lambda_3d_pos: 1.0
lambda_3d_velocity: 20.0
lambda_scale: 0.5
lambda_lv: 0.0
lambda_lg: 0.0
lambda_a: 0.0
lambda_av: 0.0

# Augmentation
synthetic: False
flip: True
mask_ratio: 0.
mask_T_ratio: 0.
noise: False
